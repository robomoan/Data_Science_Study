{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_CNN_fashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lQeEMykdCPqoqeOgperh-zjb_g2Xeb3K",
      "authorship_tag": "ABX9TyPRiWWp+DUfNcyotj09NB28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robomoan/Data_Science_Study/blob/main/Projects/Project_CNN_fashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeMwXx9dKulx"
      },
      "source": [
        "# Classifying fashion MNIST data with CNN\n",
        "## Beomhwan Roh (노범환)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXD4tq_7K2RE"
      },
      "source": [
        "### 개요 및 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgPkWnX5LCDl"
      },
      "source": [
        "옷 이미지를 이용해 10가지의 옷 종류로 분류하는 딥러닝 모델을 만들고자 한다. kaggle에서 fashion MNIST 데이터 (https://www.kaggle.com/zalando-research/fashionmnist) 를 다운받고, 구글 드라이브에 마운트하여 colaboratory로 진행하였다.  \n",
        "  \n",
        "각 이미지는 28x28의 픽셀의 흑백 이미지이며, 하나의 샘플에는 1~255까지의 각 픽셀의 밝기를 담고 있다.  \n",
        "  \n",
        "각 샘플의 label은 0~9 사이의 정수이며 각 label의 의미는 다음과 같이 주어진다.  \n",
        "0 - 티셔츠, 1 - 바지, 2 - 풀오버(스웨터), 3 - 드레스, 4 - 코트, 5 - 샌들, 6 - 셔츠, 7 - 스니커, 8 - 가방, 9 - 앵클 부츠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CgDJ1kkKt_v"
      },
      "source": [
        "# 라이브러리 부르기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56n9FJQiQKmU",
        "outputId": "fa287d7e-0f20-447d-984d-dc6f1994528b"
      },
      "source": [
        "# 데이터셋 부르기\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/fashion-mnist_train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/fashion-mnist_test.csv\")\n",
        "\n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 785) (10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "anG41uaGQtpp",
        "outputId": "bf553586-88d2-40cb-b045-b698679d39ec"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>92</td>\n",
              "      <td>101</td>\n",
              "      <td>107</td>\n",
              "      <td>100</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>211</td>\n",
              "      <td>220</td>\n",
              "      <td>214</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>222</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>214</td>\n",
              "      <td>163</td>\n",
              "      <td>146</td>\n",
              "      <td>165</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>183</td>\n",
              "      <td>112</td>\n",
              "      <td>55</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>102</td>\n",
              "      <td>165</td>\n",
              "      <td>160</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>188</td>\n",
              "      <td>163</td>\n",
              "      <td>93</td>\n",
              "      <td>...</td>\n",
              "      <td>171</td>\n",
              "      <td>249</td>\n",
              "      <td>207</td>\n",
              "      <td>197</td>\n",
              "      <td>202</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>69</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>74</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>136</td>\n",
              "      <td>147</td>\n",
              "      <td>144</td>\n",
              "      <td>121</td>\n",
              "      <td>102</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      2       0       0       0  ...         0         0         0         0\n",
              "1      9       0       0       0  ...         0         0         0         0\n",
              "2      6       0       0       0  ...         0         0         0         0\n",
              "3      0       0       0       0  ...         0         0         0         0\n",
              "4      3       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xpidc9GRFS9"
      },
      "source": [
        "train 데이터 셋은 60000개의 샘플을, test 데이터셋은 10000개의 샘플을 가지고 있으며 각각의 샘플은 label과 28x28 = 784개의 픽셀 데이터를 가지고 있다.  \n",
        "train 데이터셋과 test 데이터셋의 label과 픽셀 데이터를 분리한다. DataFrame형 데이터를 numpy 배열로 바꿔주고 1차원으로 늘여진 각 샘플의 픽셀 데이터를 2차원 데이터로 변환해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibT5MK6kRrxa"
      },
      "source": [
        "# 첫번째 열을 label 데이터로, 나머지 열들을 input 데이터로 분리\n",
        "# DataFrame형을 numpy 배열로 변환\n",
        "train_label, train_input = train.iloc[:,0].to_numpy(), train.iloc[:, 1:].to_numpy()\n",
        "test_label, test_input = test.iloc[:, 0].to_numpy(), test.iloc[:, 1:].to_numpy()\n",
        "\n",
        "# input 데이터셋의 1차원 데이터를(784) 2차원 데이터(28x28)로 변환하기\n",
        "train_pixel = train_input.reshape(-1, 28, 28)\n",
        "test_pixel = test_input.reshape(-1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ2tD57_R5r3",
        "outputId": "ba7767cd-d9e1-4cdf-f36f-5dc7639c69a6"
      },
      "source": [
        "print(train_label.shape, train_pixel.shape)\n",
        "print(test_label.shape, test_pixel.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,) (60000, 28, 28)\n",
            "(10000,) (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaHpHQJNY4C3"
      },
      "source": [
        "픽셀 데이터는 다음과 같이 그릴 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "J9jQzXOGY7UQ",
        "outputId": "25e48e27-dd47-41f1-9790-fe4140e469e1"
      },
      "source": [
        "plt.imshow(train_pixel[0], cmap = 'gray_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAsh4gJXZjY1"
      },
      "source": [
        "픽셀 데이터를 이용해 CNN 모델을 훈련하고자 한다. 훈련된 모델로 픽셀 데이터의 label을 예측해본다.  \n",
        "  \n",
        "모델을 훈련하기 앞서 데이터를 scale한다. 1\\~255 사이의 데이터를 훈련하면 weight의 변동성이 커질 수 있어 이를 0\\~1 사이의 값으로 맞추기 위해 각 픽셀값에 255를 나눠준다.\n",
        "  \n",
        "또한 CNN 모델에 훈련하기 위해 픽셀 데이터에 층을 추가한다. 컬러 데이터라면 RGB의 3개 층을 사용했겠지만, 흑백 데이터이므로 1개의 층만을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WpxQLV3Wb65",
        "outputId": "bb6a988f-a980-4ac4-c20a-ef8c5a85cdff"
      },
      "source": [
        "# 훈련 데이터와 테스트 데이터 scale, 층 추가\n",
        "train_scaled = train_pixel.reshape(-1, 28, 28, 1) / 255.0\n",
        "test_scaled = test_pixel.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "print(train_scaled.shape, test_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-JsH_sdfI3g"
      },
      "source": [
        "모델 훈련중 모델을 검증하기 위한 검증 데이터를 훈련 데이터에서 분리한다. 훈련 데이터의 20%를 무작위로 뽑아 검증 데이터로 분리한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t7TtLEPeDiY"
      },
      "source": [
        "# 훈련 데이터에서 검증 데이터 분리\n",
        "train_scaled_seperated, val_scaled, train_label_seperated, val_label = train_test_split(\n",
        "    train_scaled, train_label, test_size = 0.2, random_state = 100\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYKwVjM7u191",
        "outputId": "0dd0730a-4e15-4a64-d532-2d8a6b608541"
      },
      "source": [
        "print(train_scaled_seperated.shape, val_scaled.shape)\n",
        "print(train_label_seperated.shape, val_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 28, 28, 1) (12000, 28, 28, 1)\n",
            "(48000,) (12000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11KEpBGlceIU"
      },
      "source": [
        "### 모델 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YnZn5m3cKGo"
      },
      "source": [
        "CNN 모델을 만든다. 모델은 3개 층의 합성곱 신경망과 1개의 일반 신경망(output)층으로 이루어져있다. 각각의 합성곱 층에는 (2, 2) max pooling을 사용하였다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAw-TTBoUhAj"
      },
      "source": [
        "# CNN 모델 만들기\n",
        "model = Sequential()\n",
        "\n",
        "# 합성곱 층: (3, 3) 사이즈의 32개 필터, same padding 적용, 활성화함수로 ReLU 적용\n",
        "model.add(Conv2D(32, kernel_size = 3, activation='relu',\n",
        "                 padding='same', input_shape=(28, 28, 1))) # 흑백 데이터이므로 1개의 층 사용\n",
        "\n",
        "# (2, 2) max pooling\n",
        "model.add(MaxPool2D(2))\n",
        "\n",
        "# 합성곱 층: (3, 3) 사이즈의 32개 필터, same padding 적용, 활성화함수로 ReLU 적용\n",
        "model.add(Conv2D(32, kernel_size = 3, activation = 'relu', padding='same'))\n",
        "\n",
        "# (2, 2) max pooling\n",
        "model.add(MaxPool2D(2))\n",
        "\n",
        "# 합성곱 층: (3, 3) 사이즈의 32개 필터, same padding 적용, 활성화함수로 ReLU 적용\n",
        "model.add(Conv2D(32, kernel_size = 3, activation = 'relu', padding='same'))\n",
        "\n",
        "# (2, 2) max pooling\n",
        "model.add(MaxPool2D(2))\n",
        "\n",
        "# 2차원 데이터를 1차원으로 변환\n",
        "model.add(Flatten())\n",
        "\n",
        "# output층, 10개 label의 분류를 위해 활성화 함수는 Softmax 적용\n",
        "model.add(Dense(10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6mgpd4mWDPl",
        "outputId": "38a6b2ce-378d-4f2a-e2f4-3213bcfea958"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2890      \n",
            "=================================================================\n",
            "Total params: 21,706\n",
            "Trainable params: 21,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPy8gYVsU1j3"
      },
      "source": [
        "모델을 컴파일 하고 훈련한다. 최적화 알고리즘은 ADAM을 이용했고 손실함수는 크로스 엔트로피를 사용했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZD3wYqKf_re",
        "outputId": "e66ccc3a-8e35-4641-a6f5-b9d63599b821"
      },
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
        "\n",
        "# 2번의 에포크 동안 검증 점수가 개선되지 않을 경우 훈련을 조기종료하고 최적의 에포크로 되돌아감\n",
        "earlystopping = EarlyStopping(patience = 2, restore_best_weights=True)\n",
        "\n",
        "# 모델 훈련\n",
        "history1 = model.fit(train_scaled_seperated, train_label_seperated, epochs = 20, validation_data = (val_scaled, val_label), \n",
        "                     callbacks = [earlystopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 36s 3ms/step - loss: 0.5507 - accuracy: 0.8015 - val_loss: 0.4135 - val_accuracy: 0.8519\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3518 - accuracy: 0.8721 - val_loss: 0.3254 - val_accuracy: 0.8841\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3100 - accuracy: 0.8881 - val_loss: 0.3197 - val_accuracy: 0.8886\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2817 - accuracy: 0.8978 - val_loss: 0.2891 - val_accuracy: 0.8995\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2636 - accuracy: 0.9044 - val_loss: 0.2728 - val_accuracy: 0.9032\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2464 - accuracy: 0.9111 - val_loss: 0.2631 - val_accuracy: 0.9067\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2339 - accuracy: 0.9154 - val_loss: 0.2661 - val_accuracy: 0.9074\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2190 - accuracy: 0.9222 - val_loss: 0.2693 - val_accuracy: 0.9050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSg2j2vejJpH"
      },
      "source": [
        "8번째 에포크에서 검증 점수가 개선되지 않아 조기종료 되고 6번째 에포크의 모델이 채택되었다. 모델의 검증 점수는 0.2661이고, accuracy는 0.9067이다.  \n",
        "  \n",
        "테스트 데이터를 적용하여 모델을 예측한 결과는 다음과 같다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDXqO9giiVpN",
        "outputId": "c804c9f3-8685-4e39-bb72-089db773a6fa"
      },
      "source": [
        "model.evaluate(test_scaled, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2572 - accuracy: 0.9074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2572263181209564, 0.9074000120162964]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFQdqRV8lgYq"
      },
      "source": [
        "0.9074의 accuracy가 나왔다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qxImtWll8zJ"
      },
      "source": [
        "### 모델 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrOouWwvl_Rf"
      },
      "source": [
        "모델의 accuracy를 개선하기 위해 hidden layer의 합성곱 층 하나를 없애는 방법을 생각할 수 있다. \n",
        "합성곱 신경망층 2개와 일반 신경망 층 1개를 이용해 모델을 만들어본다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLaIP3bLlaAp"
      },
      "source": [
        "# 합성곱 층을 2개만 사용\n",
        "model2 = Sequential()\n",
        "\n",
        "# 합성곱 층: (3, 3) 사이즈의 32개 필터, same padding 적용, 활성화함수로 ReLU 적용\n",
        "model2.add(Conv2D(32, kernel_size = 3, activation='relu',\n",
        "                 padding='same', input_shape=(28, 28, 1)))\n",
        "\n",
        "# (2, 2) max pooling\n",
        "model2.add(MaxPool2D(2))\n",
        "\n",
        "# 합성곱 층: (3, 3) 사이즈의 32개 필터, same padding 적용, 활성화함수로 ReLU 적용\n",
        "model2.add(Conv2D(32, kernel_size = 3, activation = 'relu', padding='same'))\n",
        "\n",
        "# (2, 2) max pooling\n",
        "model2.add(MaxPool2D(2))\n",
        "\n",
        "# 2차원 데이터를 1차원으로 변환\n",
        "model2.add(Flatten())\n",
        "\n",
        "# output층, 10개 label의 분류를 위해 활성화 함수는 Softmax 적용\n",
        "model2.add(Dense(10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSYretQxnskE",
        "outputId": "770be93c-4ccb-4d71-bafb-b90cb2b82807"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                15690     \n",
            "=================================================================\n",
            "Total params: 25,258\n",
            "Trainable params: 25,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJGccNF-oRnk"
      },
      "source": [
        "마찬가지로 수정된 모델을 컴파일하고 훈련한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6zy__nmnxCx",
        "outputId": "864c1447-d38c-4103-a943-6b40d09c89c2"
      },
      "source": [
        "# 모델 컴파일\n",
        "model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
        "\n",
        "# 모델 훈련\n",
        "history2 = model2.fit(train_scaled_seperated, train_label_seperated, epochs = 20, validation_data = (val_scaled, val_label), \n",
        "                     callbacks = [earlystopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4916 - accuracy: 0.8225 - val_loss: 0.3726 - val_accuracy: 0.8633\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3347 - accuracy: 0.8817 - val_loss: 0.3161 - val_accuracy: 0.8910\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2940 - accuracy: 0.8947 - val_loss: 0.2823 - val_accuracy: 0.9011\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2701 - accuracy: 0.9036 - val_loss: 0.2774 - val_accuracy: 0.9022\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2486 - accuracy: 0.9115 - val_loss: 0.2803 - val_accuracy: 0.9013\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2322 - accuracy: 0.9160 - val_loss: 0.2531 - val_accuracy: 0.9105\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2173 - accuracy: 0.9209 - val_loss: 0.2597 - val_accuracy: 0.9082\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2042 - accuracy: 0.9261 - val_loss: 0.2484 - val_accuracy: 0.9122\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1932 - accuracy: 0.9303 - val_loss: 0.2474 - val_accuracy: 0.9164\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1843 - accuracy: 0.9330 - val_loss: 0.2435 - val_accuracy: 0.9143\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1744 - accuracy: 0.9367 - val_loss: 0.2449 - val_accuracy: 0.9163\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9393 - val_loss: 0.2736 - val_accuracy: 0.9088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjrirkbYpS7h"
      },
      "source": [
        "12번째 에포크에서 검증점수가 개선되지 않아 조기종료되고 10번째 에포크의 모델이 채택되었다. 모델의 검증점수는 0.2435, accuracy는 0.9143으로 이전 모델보다 개선되었음을 알 수 있다.  \n",
        "  \n",
        "테스트 데이터를 적용하여 모델을 예측한 결과는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGNZQHPUobd3",
        "outputId": "0fc2fe10-e302-4713-9683-99412fc7deb9"
      },
      "source": [
        "model2.evaluate(test_scaled, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2357 - accuracy: 0.9158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23568877577781677, 0.9157999753952026]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPYIishZpxIl"
      },
      "source": [
        "테스트 데이터에 대한 accuracy는 0.9158로 이전 모델보다 더 좋아졌음을 볼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FRouvxjp6XW"
      },
      "source": [
        "모델의 accuracy를 더 향상 시키기 위해 합성곱 층에서 사용하는 필터의 개수를 늘리는 방법을 생각해 볼 수 있다. 첫번째 합성곱 층에서 사용하는 필터의 개수를 32개에서 64개로 늘려본 다음 모델을 훈련시켜본다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLubR-fgpMLn"
      },
      "source": [
        "# 첫번째 합성곱 층의 필터를 64개 사용\n",
        "model3 = Sequential()\n",
        "\n",
        "# 합성곱 층: (3, 3) 사이즈의 64개 필터, same padding 적용, 활성화함수로 ReLU 적용\n",
        "model3.add(Conv2D(64, kernel_size = 3, activation='relu',\n",
        "                 padding='same', input_shape=(28, 28, 1)))\n",
        "\n",
        "# (2, 2) max pooling\n",
        "model3.add(MaxPool2D(2))\n",
        "\n",
        "# 합성곱 층: (3, 3) 사이즈의 32개 필터, same padding 적용, 활성화함수로 ReLU 적용\n",
        "model3.add(Conv2D(32, kernel_size = 3, activation = 'relu', padding='same'))\n",
        "\n",
        "# (2, 2) max pooling\n",
        "model3.add(MaxPool2D(2))\n",
        "\n",
        "# 2차원 데이터를 1차원으로 변환\n",
        "model3.add(Flatten())\n",
        "\n",
        "# output층, 10개 label의 분류를 위해 활성화 함수는 Softmax 적용\n",
        "model3.add(Dense(10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_yR1UrgrOYp",
        "outputId": "06025039-bd73-4866-f38a-7d60d72efc35"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 14, 14, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                15690     \n",
            "=================================================================\n",
            "Total params: 34,794\n",
            "Trainable params: 34,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwLJapxusdVM"
      },
      "source": [
        "마찬가지로 수정된 모델을 컴파일하고 훈련한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFE2aE5-rQKf",
        "outputId": "2ba099e0-b3e6-463e-e5f4-98d070c414a8"
      },
      "source": [
        "# 모델 컴파일\n",
        "model3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
        "\n",
        "# 모델 훈련\n",
        "history3 = model3.fit(train_scaled_seperated, train_label_seperated, epochs = 20, validation_data = (val_scaled, val_label), \n",
        "                     callbacks = [earlystopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4803 - accuracy: 0.8264 - val_loss: 0.3485 - val_accuracy: 0.8772\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3250 - accuracy: 0.8843 - val_loss: 0.2995 - val_accuracy: 0.8942\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2811 - accuracy: 0.8999 - val_loss: 0.2761 - val_accuracy: 0.9007\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2533 - accuracy: 0.9087 - val_loss: 0.2812 - val_accuracy: 0.8995\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2297 - accuracy: 0.9177 - val_loss: 0.2537 - val_accuracy: 0.9099\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2138 - accuracy: 0.9223 - val_loss: 0.2559 - val_accuracy: 0.9093\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1986 - accuracy: 0.9281 - val_loss: 0.2431 - val_accuracy: 0.9141\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1849 - accuracy: 0.9331 - val_loss: 0.2436 - val_accuracy: 0.9157\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1742 - accuracy: 0.9366 - val_loss: 0.2480 - val_accuracy: 0.9143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJeA2qSotKbo"
      },
      "source": [
        "9번째 에포크에서 검증점수가 개선되지 않아 조기종료되고 7번째 에포크의 모델이 채택되었다. 모델의 검증점수는 0.2431, accuracy는 0.9141으로 이전 모델보다 뚜렷하게 개선되었다고 보기 어렵다.  \n",
        "  \n",
        "테스트 데이터를 적용하여 모델을 예측한 결과는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq_2mvjzsqqS",
        "outputId": "549838e6-406d-4f84-b7ab-7d9bfdfea6f1"
      },
      "source": [
        "model3.evaluate(test_scaled, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2396 - accuracy: 0.9159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23964279890060425, 0.9158999919891357]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1jjFxXxtySM"
      },
      "source": [
        "accuracy는 0.9159로 두번째 모델보다 뚜렷하게 개선되었다고 보기 어렵고 비슷한 성능을 가진다고 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNqYeZPNuORT"
      },
      "source": [
        "### 분석 및 결론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luGu_6BBuQJl"
      },
      "source": [
        "첫번째 모델 `model`과 두번째 모델 `model2`의 차이는 합성곱 신경망 층의 개수이다. 두 모델의 `.summary()`를 비교해보았을때 합성곱 층은 하나가 줄었지만 모델의 전체 parameter 개수는 오히려 늘어난 것을 볼 수 있다. \n",
        "   \n",
        "첫번째 모델에서 데이터가 마지막 합성곱 층을 통과하였을 때 데이터의 shape는 (3, 3, 32)였다. 각 필터당 9(=3x3)개의 데이터를 이용해 분류하기에는 데이터의 특징적인 부분이 부족해보인다.\n",
        "max pooling은 데이터의 특징적인 부분을 제외한 나머지를 제거함으로써 이를 부각시켜주고 모델의 훈련을 용이하게 하지만, 과도하게 사용하였을 경우 데이터의 손실을 가져온다는 점을 알 수 있다.  \n",
        "  \n",
        "두번째 모델 `model2`와 세번째 모델 `model3`의 차이는 합성곱 신경망 층의 필터의 개수다. 필터의 개수가 늘어나면서 전체 parameter 개수도 늘어났지만 모델은 크게 개선되지 않았다. 10가지 옷 종류를 분류하는데 필터는 32개로 이미 충분하고 필터를 과도하게 늘리면 오히려 분류 능력을 방해할 수 있음을 알 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-GzFfeU5xKB"
      },
      "source": [
        "### 참고자료\n",
        "\n",
        " - \"Fashin MNIST\", *kaggle*, 2017년 12월 7일 수정, 2021년 6월 12일 접속, https://www.kaggle.com/zalando-research/fashionmnist\n",
        " - 박재우 교수님, *Convolutional Neural Networks* (딥러닝 수업자료, 2021-1학기)\n",
        " - 박재우 교수님, *Demo5_tensorflow_CIFAR_Tutorial.ipynb* (딥러닝 수업자료 2021-1학기)\n",
        " - 박해선, *혼자 공부하는 머신러닝 + 딥러닝* (한빛미디어, 2021), 444-460"
      ]
    }
  ]
}